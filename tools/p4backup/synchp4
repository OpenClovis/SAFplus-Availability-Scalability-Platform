#!/bin/bash
#
# Sync the "vault" perforce client. Download the complete set of
# changelists for the most recent day.  Make a gzip'ed tar archive
# of the synced vault, including the changelists.

declare -x PATH=/usr/local/bin:${PATH}
declare -x P4CLIENT="vault"
declare -x P4USER="perforce"
declare -x P4PORT="192.168.0.3:1666"

VAULT_DIR="/vault"
SYNC_LOCK="${VAULT_DIR}/sync_lock"
DEPOT_DIR="${VAULT_DIR}/depot"
BACKUP_DIR="${VAULT_DIR}/depot_backup"

TMP_DIR="${VAULT_DIR}/temp"
TMP_FILE=`mktemp -q ${TMP_DIR}/p4sync.XXXXXX`
if [ $? -ne 0 ]
then
    echo "Failed to create temp file for p4sync"
    exit 1
fi

OPTS="bsch"
LONGOPTS="backup,sync,changes,help"
usage() {
    echo "Usage: p4sync [--backup] [--sync] [--changes] [--help]"
    if [ $# -gt 0 ]
    then
        echo "Sync and backup the perforce database locally"
        echo ""
        echo "  -b, --backup    Make daily backup of local depot copy"
        echo "  -s, --sync      Sync local depot copy with perforce server"
        echo "  -c, --changes   Get latest set of changeslists"
        echo "  -h, --help      Print this help message and exit"
        echo ""
        echo "With no arguments, do the --backup, the --sync, and the"
        echo "--changes operations"
        echo ""
        echo ""
    fi
    return 0
}

sendmail() {
    if [ $# -lt 1 ]
    then
        echo "sendmail usage: sendmail subject"
        return 1
    fi

    SUBJ="$1 `date`"
    RECIPIENTS="breck@openclovis.com anuj@openclovis.com zsolt@openclovis.com"
    #RECIPIENTS="breck@openclovis.com "
    mail -s "${SUBJ}" ${RECIPIENTS}
    return 0
}

changelists() {
    # Fudge factor specifies how many changelists to download at a time
    # Get all changelists by setting FUDGE_FACTOR to ""
    echo "getting changelist"
    FUDGE_FACTOR="-m 5000"
    CHANGES_DIR=${VAULT_DIR}/changelists
    CHANGES_FILE=${CHANGES_DIR}/changes_done
    declare -a done_changes
    declare -a new_changes
    declare -i idx

    # Go over the list of all changelist that we have imported, or
    # rather over all the changelists whose explanations we have
    # imported.  Load those changelist numbers into our "done" array.
    # Then, get the list of changeslists that are not pending.
    # If a given changelist is NOT in our list of "done" changelists
    # then grab the changelist's explanation and store it.  That
    # explanation should include the diffs.
    #
    # Another way we could do this would be to just check whether we
    # have a changelist explanation file for the changelist in question.
    # It seemed that just checking an entry in an array would be
    # quicker checking for the existence of the file.  Another advantage
    # is that this way we can move the changelist files somewhere else
    # and still maintain a memory of which lists are done.  Probably a stupid
    # concern.  Probably should have just gone for simplicity.  But,
    # I am just too much a fan of my own cleverness.
    while read line
    do
        let idx=$line
        done_changes[idx]=1
    done < ${CHANGES_FILE}

    # OK, the VPN to bangalore is very very flaky.  Sometimes it takes
    # quite a long time to download the list of changelists.  So, when
    # we download the list, save a copy of it.  When next we come through
    # here if we see the copy sitting around then we try using that copy
    # instead of getting it from perforce.  If we successfully process all
    # of the changeslists on the saved list then we remove it before we
    # return.
    # I know, it's a kludge.  But it is so annoying to wait for the
    # p4 changes only to have it lock up while describing a change.
    if [ -f ${CHANGES_DIR}/new_changelsits ]
    then
        echo "USING SAVED LIST OF CHANGELISTS"
        CHANGE_LISTS=`cat ${CHANGES_DIR}/new_changelists`
    else
        CHANGE_LISTS=`p4 changes ${FUDGE_FACTOR} | grep -v ' \*pending\* ' |
        awk '{print $2;}' | sort -n | tee ${CHANGES_DIR}/new_changelists`
    fi
    for change_list in ${CHANGE_LISTS}
    do
        let idx=$change_list
        if [ "${done_changes[idx]}" = 1 ]
        then
            continue
        fi
        new_changes[${#new_changes[@]}]=$idx
    done

    let idx=0
    while [ "$idx" -lt "${#new_changes[@]}" ]
    do
        change=${new_changes[idx]}
        p4 describe -du ${change} > ${CHANGES_DIR}/${change}
        if [ $? -ne 0 ]
        then
            echo "Failure describing ${change}"
            rm -f ${CHANGES_DIR}/${change}
            return 1
        fi
        echo ${change} >> ${CHANGES_FILE}
        let idx++
    done
    rm -f ${CHANGES_DIR}/new_changelists
    return 0
}

backup() {
    echo "making backup"
    declare -i keep=20
    cd ${VAULT_DIR}
    TODAY=`date +%Y%m%d`
    NAME="${BACKUP_DIR}/depot_backup${TODAY}.tgz"
    if [ -f "${NAME}" ]
    then
        echo "The depot backup: ${NAME} is already present"
        return 1
    fi
    touch ${NAME}
    if [ ! -f ${NAME} ]
    then
        echo "Cannot create depot backup: ${NAME}"
        return 1
    fi

    #
    # It is possible that the date has been set back on this machine.
    # Let's do a primitive check.  Look at the date part of all the
    # backup files.  Compare the date part of the name of the file
    # we're about to create.  If the current date is numerically
    # less than the date from any previously existing files then
    # something screwy has happened with the date.  This check cannot
    # tell the difference between the date being incorrectly set
    # to a time in the past and having the date corrected after
    # having files generated that look like they're in the future.
    # But humans can look at the error and figure out what to do
    # with it.
    # Note that I'm not going to be messing with the date on the
    # system, so this code can't really be tested.
    DATE_LIST=`ls ${BACKUP_DIR}/depot_backup[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9].tgz |
        sed -e 's;^.*/depot_backup;;' -e 's/.tgz//'`
    for i in ${DATE_LIST}
    do
        # Test is -lt and not -le because we've already tested for
        # equality above
        if [ ${TODAY} -lt ${i} ]
        then
            echo ""
            echo "****"
            echo "There exist files in ${BACKUP_DIR} that are for later"
            echo "dates than today's backup file: ${NAME}"
            echo "One example is depot_backup${i}.tgz"
            return 1
        fi
    done

    D="`basename ${DEPOT_DIR}`/dev"
    # Doing a tar backup of the whole depot takes almost 3 hours.  It
    # yields a tgz file that is almost 15GB.  That is undesirable because
    # 1) the bigger the file, the greater the chance that a bad block will
    # cause the loss of the whole archive, 2) Three freaking hours?!?
    # This should get everything that will be changeing.  Why waste
    # the disk space and the time.  Zsolt has accepted this tradeoff.
    tar czf ${NAME} ${D}/main ${D}/RC2/R2.2-Mercury ${D}/RC2/CWorks
    if [ $? -ne 0 ]
    then
        echo "Archive creation failed: ${NAME}"
        return 1
    fi

    declare -i count=`ls ${BACKUP_DIR}/depot_backup[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9].tgz | wc -l`
    let count-=keep
    if [ $count -gt 0 ]
    then
        echo "Removing the $count backup files:"
        ls ${BACKUP_DIR}/depot_backup[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9].tgz |
        sort | head -$count 

        ls ${BACKUP_DIR}/depot_backup[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9].tgz |
        sort | head -$count |
        xargs rm -f
    fi
    return 0
}

p4sync() {
    cd ${DEPOT_DIR}
    echo "Doing sync in ${DEPOT_DIR}"
    p4 sync ./...
    STATUS=$?
    if [ ${STATUS} -ne 0 ]
    then
        echo "sync failed"
        rm ${SYNC_LOCK}
        return 1
    fi
    return 0
}


if [ -f ${SYNC_LOCK} ]
then
    PID=`cat ${SYNC_LOCK}`
    echo "sync is already running, PID = ${PID}" | sendmail "sync failure" 
    exit 1
fi
echo "$$" > ${SYNC_LOCK}

trap "rm -f ${SYNC_LOCK}" exit

#
# Parse arguments.  Check which function we're being called to perform.
# Do the sync?  Do the backup?  Download the changes?  If none are
# specifically requested then we must be getting called as default
# which implies we're being called to do all three.
BACKUP=""
SYNC=""
CHANGES=""

eval set -- `getopt --options="${OPTS}" --longoptions="${LONGOPTS}" -- "$@"`
while [ $# -gt 0 ]
do
    case "$1" in
    -h|--help)
        usage --verbose
        exit 0
        ;;
    -c|--changes)
        CHANGES=true
        ;;
    -s|--sync)
        SYNC=true
        ;;
    -b|--backup)
        BACKUP=true
        ;;
    --)
        shift
        break
        ;;
    *)
        usage
        exit 1
        ;;
    esac
    shift
done


#
# If we have another argument left then someone must have passed a bogus
# argument.
if [ $# -gt 0 ]
then
    usage
    exit 1
fi

# If we were not called with any argument then we have to do everything
if [ "${CHANGES}" = "" -a "${SYNC}" = "" -a "${BACKUP}" = "" ]
then
    CHANGES=true
    SYNC=true
    BACKUP=true
fi


# OVERRIDE HERE.  While we're just testing, turn features off except
# what we're specifically testing.
#CHANGES=""
#SYNC=""
#BACKUP=""

# First, if we need to backup, we should backup whatever we have from
# yesterday.
if [ "${BACKUP}" != "" ]
then
    backup >& ${TMP_FILE}
    if [ $? -ne 0 ]
    then
        sendmail "backup failure" < ${TMP_FILE}
        rm ${TMP_FILE}
        exit 1
    fi
fi

# Sync the perforce client to the local directory
if [ "${SYNC}" != "" ]
then
    p4sync >> ${TMP_FILE} 2>&1
    if [ $? -ne 0 ]
    then
        sendmail "sync failure" < ${TMP_FILE}
        rm ${TMP_FILE}
        exit 1
    fi
fi

# Download the changelists
if [ "${CHANGES}" != "" ]
then
    changelists >> ${TMP_FILE} 2>&1
    if [ $? -ne 0 ]
    then
        sendmail "Failure getting changelists" < ${TMP_FILE}
        rm ${TMP_FILE}
        exit 1
    fi
fi

sendmail "p4sync success" << EOF
Sync of vault seems to have been a success
`egrep -v '^\/\/depot.* - .* \/vault' ${TMP_FILE}`
EOF

rm ${TMP_FILE}
